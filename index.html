<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Record and save your stories">
  <meta name="theme-color" content="#ff5252">
  <link rel="manifest" href="./manifest.json">
  <link rel="icon" href="./icons/icon-192.png">
  <link rel="apple-touch-icon" href="./icons/icon-192.png">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link href="https://fonts.googleapis.com/css2?family=Baloo+2:wght@400;600;800&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="./styles/style.css">
  <title>My Story Recorder</title>
</head>
<body>
  <header>
    <nav aria-label="Main navigation">
      <a href="./index.html" class="nav-link active" aria-label="Record">üéôÔ∏è</a>
      <a href="./history.html" class="nav-link" aria-label="History">üìö</a>
      <a href="./kids.html" class="nav-link" aria-label="Kids">üëß</a>
      <a href="./settings.html" class="nav-link" aria-label="Settings">‚öôÔ∏è</a>
    </nav>
    <div id="offlineBanner" class="offline-banner hidden" role="alert">
      üì¥ You're offline ‚Äî recordings will be saved locally
    </div>
  </header>

  <main>
    <h1>üìñ My Story</h1>
    <p id="kidName" class="subtitle"></p>

    <button id="recordBtn" class="big-button" aria-label="Start recording">
      üé§ Start Recording
    </button>

    <div id="recording-indicator" class="recording-indicator hidden" aria-live="polite">
      <span class="pulse-dot"></span> Recording‚Ä¶
      <span id="timer">00:00</span>
    </div>

    <div id="liveTranscript" class="card hidden" aria-live="polite">
      <label>‚ú® Live transcript</label>
      <p id="transcriptText" class="transcript-preview">Listening‚Ä¶</p>
    </div>

    <div id="toast" class="toast hidden" role="status" aria-live="polite"></div>
  </main>

  <script type="module">
    import { showCurrentKid, showToast, updateOnlineStatus } from './scripts/app.js';
    import { startRecording, stopRecording } from './scripts/recorder.js';
    import { isSupported, startRecognition, stopRecognition } from './scripts/speech-recognition.js';

    const btn = document.getElementById('recordBtn');
    const indicator = document.getElementById('recording-indicator');
    const timerEl = document.getElementById('timer');
    const liveTranscript = document.getElementById('liveTranscript');
    const transcriptText = document.getElementById('transcriptText');
    let isRecording = false;
    let timerInterval = null;
    let seconds = 0;

    if (!isSupported) {
      showToast('Speech-to-text not supported in this browser. Try Chrome or Edge.', 'error');
    }

    function updateTimer() {
      seconds++;
      const m = String(Math.floor(seconds / 60)).padStart(2, '0');
      const s = String(seconds % 60).padStart(2, '0');
      timerEl.textContent = `${m}:${s}`;
    }

    btn.addEventListener('click', async () => {
      if (!isRecording) {
        try {
          // Start speech recognition FIRST on Android, before getUserMedia
          // grabs the mic ‚Äî otherwise Android's speech service is blocked.
          if (isSupported) {
            startRecognition({
              onUpdate: (text) => {
                transcriptText.textContent = text || 'Listening‚Ä¶';
              },
            });
          }

          await startRecording();
          isRecording = true;
          btn.textContent = '‚èπÔ∏è Stop Recording';
          btn.classList.add('recording');
          indicator.classList.remove('hidden');
          liveTranscript.classList.remove('hidden');
          transcriptText.textContent = 'Listening‚Ä¶';
          seconds = 0;
          timerInterval = setInterval(updateTimer, 1000);
        } catch (err) {
          // If mic access fails, also stop speech recognition
          if (isSupported) stopRecognition();
          showToast('Could not access microphone. Please allow mic access.', 'error');
        }
      } else {
        clearInterval(timerInterval);

        // Stop both audio recording and speech recognition
        const audioBlob = await stopRecording();
        const transcript = isSupported ? stopRecognition() : '';

        isRecording = false;
        btn.textContent = 'üé§ Start Recording';
        btn.classList.remove('recording');
        indicator.classList.add('hidden');
        liveTranscript.classList.add('hidden');

        // Store audio blob AND transcript in IndexedDB
        const { savePendingRecording } = await import('./scripts/storage.js');
        await savePendingRecording(audioBlob, transcript);
        window.location.href = './review.html';
      }
    });

    showCurrentKid();
    updateOnlineStatus();
  </script>
</body>
</html>
